{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Model"
      ],
      "metadata": {
        "id": "RqFrMVo-anhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L8UpOOTYUZTW"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing JSON File"
      ],
      "metadata": {
        "id": "PFN8Aq3AZl6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('intents.json','r') as f:\n",
        "  data=json.load(f)\n",
        "\n",
        "texts=[]\n",
        "intents=[]\n",
        "for item in data['rasa_nlu_data']['common_examples']:\n",
        "  texts.append(item['text'])\n",
        "  intents.append(item['intent'])\n",
        "\n",
        "\n",
        "unique_intents=sorted(list(set(intents)))\n",
        "intent_to_id={intent_name: i for i, intent_name in enumerate(unique_intents)}\n",
        "id_to_intent={i: intent_name for i, intent_name in enumerate(unique_intents)}\n",
        "\n",
        "labels=[intent_to_id[intent] for intent in intents]\n"
      ],
      "metadata": {
        "id": "r82D1r3zU3Ds"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing this thing"
      ],
      "metadata": {
        "id": "hyDQXZiFZuiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encodings =tokenizer(texts, truncation=True, padding=True, max_length=512)\n"
      ],
      "metadata": {
        "id": "4klT_JAnZziz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the JSON to pytorch Dataset\n"
      ],
      "metadata": {
        "id": "RDmnT-nzavdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class InvestmentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # This correctly creates a dictionary for a single item\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # This adds the corresponding single label\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "dataset=InvestmentDataset(encodings,labels)\n"
      ],
      "metadata": {
        "id": "Er0gg7Yma2ta"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making a data collator"
      ],
      "metadata": {
        "id": "eYDy4SDOke3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "UmgKryL9klpL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Trainer"
      ],
      "metadata": {
        "id": "bX0pdcl4eNfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "num_labels=len(unique_intents)\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\",num_labels=num_labels)\n",
        "\n",
        "training_args=TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    learning_rate=5e-5,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4IJ03ideVWk",
        "outputId": "ac5ebf18-25f6-404c-f35d-f6660dd13240"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Making the model do hoola hoops*\n",
        "\n",
        "Theres a value error so i need to do hoola hoops to make it work now.\n",
        "\n",
        "Wrong model was being called hehe"
      ],
      "metadata": {
        "id": "t4HndPp2gUC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "save_directory=\"./trained_model_0.1\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(\"Hoola Hoops are done\")\n",
        "\n",
        "with open(f'{save_directory}/mappings.json', 'w') as f:\n",
        "    json.dump({'intent_to_id': intent_to_id, 'id_to_intent': id_to_intent}, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "JrUB-UWEgb0b",
        "outputId": "65a0521a-c15e-4ad2-a26b-aeb114ca438c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 01:33, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.757300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.551800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.368400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.117100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.912700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.839900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.804500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hoola Hoops are done\n"
          ]
        }
      ]
    }
  ]
}